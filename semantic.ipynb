{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590672da-41ac-4d86-a889-7e5d0f8f74ee",
   "metadata": {},
   "source": [
    "## Similaridade Semantica\n",
    "Localizar dentro de um texto oferecido a similaridade com uma frase pré determinada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314cfdde-2245-4ce4-abac-7cc7abe989e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow_text  \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import AutoTokenizer, TFAutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b41b1-e0bd-4baa-a2d8-f2a56659ff3d",
   "metadata": {},
   "source": [
    "# LaBSE Embbeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a460fb6-d92a-4f26-b66b-6553c5563d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 18:33:09.022921: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Pro\n",
      "2025-09-02 18:33:09.023076: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-09-02 18:33:09.023082: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1756848789.023580 7144479 pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1756848789.023632 7144479 pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Carrega tokenizer e modelo LaBSE\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/LaBSE\")\n",
    "model = TFAutoModel.from_pretrained(\"sentence-transformers/LaBSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c7750e-754a-4949-b7c0-243f65d84bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para tokenizar e preparar inputs para o modelo LaBSE\n",
    "def preprocess(texts):\n",
    "    tokens = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": tokens[\"input_ids\"],\n",
    "        \"input_mask\": tokens[\"attention_mask\"],\n",
    "        \"segment_ids\": tf.zeros_like(tokens[\"input_ids\"]) \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d35f676-a30f-4408-a0c4-90b7d73f6a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frases base\n",
    "texts = [\n",
    "    \"O produto chegou quebrado.\",\n",
    "    \"O atendimento foi excelente.\",\n",
    "    \"Entrega rápida e segura.\",\n",
    "    \"Não gostei da qualidade.\",\n",
    "    \"O item está com defeito.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8aa10fb-6194-49eb-8d3d-fa76f0720e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frase de busca (query)\n",
    "queries = [\"produto com defeito\", \n",
    "         \"chegou quebrado\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f15632b-3bba-4c9b-a044-acff4fcde5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query: \"produto com defeito\"\n",
      "Frase mais similar: \"O item está com defeito.\"\n",
      "Score: 0.7929\n",
      "\n",
      "Query: \"chegou quebrado\"\n",
      "Frase mais similar: \"O produto chegou quebrado.\"\n",
      "Score: 0.6929\n"
     ]
    }
   ],
   "source": [
    "# Tokenização\n",
    "text_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "query_inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "# Geração dos embeddings\n",
    "#outputs = model(inputs)\n",
    "text_embeddings = model(**text_inputs).last_hidden_state[:, 0, :]  # [CLS]\n",
    "query_embeddings = model(**query_inputs).last_hidden_state[:, 0, :]  # [CLS]\n",
    "\n",
    "# Similaridade de cosseno\n",
    "similarity_matrix = cosine_similarity(query_embeddings.numpy(), text_embeddings.numpy())\n",
    "\n",
    "# Exibir resultados\n",
    "for i, query in enumerate(queries):\n",
    "    scores = similarity_matrix[i]\n",
    "    idx = np.argmax(scores)\n",
    "    print(f\"\\nQuery: \\\"{query}\\\"\")\n",
    "    print(f\"Frase mais similar: \\\"{texts[idx]}\\\"\")\n",
    "    print(f\"Score: {scores[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794eaf8-16e9-44f3-9930-44c9b7f7a654",
   "metadata": {},
   "source": [
    "## Cria uma função para ser aplicável a diferentes tipos de inteção "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b03bbc8b-24c7-4ebd-89fd-1e58601720f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função de similaridade\n",
    "def buscar_similares(texts, queries, categoria=None, top_n=1, threshold=0.5):\n",
    "    # Tokeniza\n",
    "    text_inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "    query_inputs = tokenizer(queries, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "    # Embeddings\n",
    "    text_embeddings = model(**text_inputs).last_hidden_state[:, 0, :]\n",
    "    query_embeddings = model(**query_inputs).last_hidden_state[:, 0, :]\n",
    "\n",
    "    # Similaridade\n",
    "    similarity_matrix = cosine_similarity(query_embeddings.numpy(), text_embeddings.numpy())\n",
    "\n",
    "    # Resultados por query\n",
    "    resultados = []\n",
    "    for i, query in enumerate(queries):\n",
    "        scores = similarity_matrix[i]\n",
    "        top_indices = scores.argsort()[::-1][:top_n]\n",
    "        top_matches = [\n",
    "            {\n",
    "                \"query\": query,\n",
    "                \"categoria\": categoria,\n",
    "                \"texto_encontrado\": texts[idx],\n",
    "                \"score\": float(scores[idx])\n",
    "            }\n",
    "            for idx in top_indices if scores[idx] >= threshold\n",
    "        ]\n",
    "        resultados.extend(top_matches)\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e2d8e780-a49c-4c2f-bb85-fc4f78ef5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Cobra o valor de R$ 1.250,00 em 8x.\",\n",
    "    \"Cobra R$10,00 pelo produto.\",\n",
    "    \"Cobrar dez reais.\",\n",
    "    \"Cobre dez conto\",\n",
    "    \"Cobra um valor de 1 real e cinquenta centavos\",\n",
    "    \"Como está o tempo hoje?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9532b2b6-3ef9-4f93-95c9-e3bfc4c1c363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'Cobra um valor', 'categoria': 'intenção de cobrança', 'texto_encontrado': 'Cobra um valor de 1 real e cinquenta centavos', 'score': 0.6940731406211853}\n",
      "\n",
      "{'query': 'Cobra o valor', 'categoria': 'intenção de cobrança', 'texto_encontrado': 'Cobre dez conto', 'score': 0.6896507740020752}\n",
      "\n",
      "{'query': 'Passa uma cobrança de dez reais', 'categoria': 'intenção de cobrança', 'texto_encontrado': 'Cobrar dez reais.', 'score': 0.8900354504585266}\n",
      "\n",
      "{'query': 'Cobra dele', 'categoria': 'intenção de cobrança', 'texto_encontrado': 'Cobre dez conto', 'score': 0.6705611348152161}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Cobra um valor\",\n",
    "     \"Cobra o valor\",\n",
    "    \"Faça uma cobrança\",\n",
    "    \"Passa uma cobrança de dez reais\",\n",
    "    \"Cobra dele\",\n",
    "    \"Cobre isso aqui\",\n",
    "    \"Cobrar o valor restante do cliente\"\n",
    "]\n",
    " \n",
    "# Precisão acima de 65% \n",
    "resultados = buscar_similares(texts, queries, categoria=\"intenção de cobrança\", threshold=0.65)\n",
    "for r in resultados:\n",
    "    print(f\"{r}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
